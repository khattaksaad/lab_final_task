{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from collections import defaultdict, namedtuple\n",
    "import fileinput\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_sents(lines):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        lines (Iterable[str]): the lines\n",
    "\n",
    "    Yields:\n",
    "        List[str]: the lines delimited by an empty line\n",
    "    \"\"\"\n",
    "    sent = []\n",
    "    stripped_lines = (line.strip() for line in lines)\n",
    "    for line in stripped_lines:\n",
    "        if line == '':\n",
    "            yield sent\n",
    "            sent = []\n",
    "        else:\n",
    "            sent.append(line)\n",
    "    yield sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Token = namedtuple('Token', 'sent_id word_id word bio tag')\n",
    "wnut_bio = ('B', 'I', 'O')\n",
    "wnut_tags = ('corporation', 'creative-work', 'group', 'location', 'person', 'product')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_tok(word, bio_tag, sent_id=-1, word_id=-1):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        word (str): the surface form of the word\n",
    "        bio_tag (str): the tag with BIO annotation\n",
    "        sent_id (int): the sentence ID\n",
    "        word_id (int): the word ID\n",
    "\n",
    "    Returns:\n",
    "        Token\n",
    "\n",
    "    Raises:\n",
    "        ValueError\n",
    "    \"\"\"\n",
    "    if bio_tag == 'O':\n",
    "        bio, tag = 'O', 'O'\n",
    "    else:\n",
    "        bio, tag = bio_tag.split('-', 1)\n",
    "        if bio not in wnut_bio or tag not in wnut_tags:\n",
    "            raise ValueError('Invalid tag: %s %s %d %d' % (word, bio_tag, sent_id, word_id))\n",
    "    return Token(sent_id, word_id, word, bio, tag)\n",
    "\n",
    "\n",
    "def token_to_conll(tok):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        tok (Token): \n",
    "\n",
    "    Returns:\n",
    "        str:\n",
    "    \"\"\"\n",
    "    return '%s\\t%s' % (tok.word, tok.tag if tok.tag == 'O' else '%s-%s' % (tok.bio, tok.tag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def line_to_toks(line, sent_id=-1, word_id=-1):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        line (str): the input line\n",
    "        sent_id (int): the current sentence ID\n",
    "        word_id (int): the current word ID\n",
    "\n",
    "    Returns:\n",
    "        Dictionary[str,Token]: the gold and guess tokens stored in a dict with keys for gold and guess\n",
    "\n",
    "    Raises:\n",
    "        ValueError\n",
    "    \"\"\"\n",
    "    def make_lbl(i):\n",
    "        return 'gold' if i == 0 else 'sys_%d' % i\n",
    "\n",
    "    try:\n",
    "        fields = line.split('\\t')\n",
    "        word = fields[0]\n",
    "        return {make_lbl(i): make_tok(word, bio_tag, sent_id, word_id)\n",
    "                for i, bio_tag in enumerate(fields[1:])}\n",
    "    except ValueError:\n",
    "        raise ValueError('Invalid line: %s %d %d' % (line, sent_id, word_id))\n",
    "\n",
    "\n",
    "def sent_to_toks(sent, sent_id=-1):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        sent (Iterator[str]): the lines that comprise a sentence\n",
    "        sent_id (int): the sentence ID\n",
    "\n",
    "    Returns:\n",
    "        Dictionary[str,List[Token]]: the gold and guess tokens for each word in the sentence,\n",
    "        stored in a dict with keys for gold and guess\n",
    "    \"\"\"\n",
    "    toks = defaultdict(list)\n",
    "    for word_id, line in enumerate(sent):\n",
    "        for src, tok in line_to_toks(line, sent_id, word_id).items():\n",
    "            toks[src].append(tok)\n",
    "    return toks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Entity = namedtuple('Entity', 'words sent_id word_id_start word_id_stop tag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def entity_to_tokens(entity):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        entity (Entity): \n",
    "\n",
    "    Returns:\n",
    "        List[Token]: \n",
    "    \"\"\"\n",
    "    def get_bio(_i):\n",
    "        if entity.tag == 'O':\n",
    "            return 'O'\n",
    "        elif _i == 0:\n",
    "            return 'B'\n",
    "        else:\n",
    "            return 'I'\n",
    "\n",
    "    return [Token(entity.sent_id, entity.word_id_start + i, word, get_bio(i), entity.tag)\n",
    "            for i, word in enumerate(entity.words)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def entity_to_conll(entity):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        entity (Entity): \n",
    "\n",
    "    Returns:\n",
    "        List[str]: a conll-formatted token tag\n",
    "    \"\"\"\n",
    "    return [token_to_conll(tok) for tok in entity_to_tokens(entity)]\n",
    "\n",
    "\n",
    "def get_phrases(entities):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        entities (Iterable[Entity]): \n",
    "\n",
    "    Returns:\n",
    "        Set[Tuple[str]]\n",
    "    \"\"\"\n",
    "    return {entity.words for entity in entities}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_phrases_and_tags(entities):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        entities (Iterable[Entity]): \n",
    "\n",
    "    Returns:\n",
    "        Set[Tuple[Tuple[str],str]]:\n",
    "    \"\"\"\n",
    "    return {(entity.words, entity.tag) for entity in entities}\n",
    "\n",
    "\n",
    "def toks_to_entities(toks):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        toks (Iterable[Token]): the tokens in a sentence\n",
    "\n",
    "    Returns:\n",
    "        Iterable[Entity]: the corresponding entities in a sentence\n",
    "\n",
    "    Raises:\n",
    "        ValueError\n",
    "    \"\"\"\n",
    "    def make_entity(tok):\n",
    "        return Entity((tok.word, ), tok.sent_id, tok.word_id, tok.word_id+1, tok.tag)\n",
    "\n",
    "    def extend_entity(entity, tok):\n",
    "        return Entity(entity.words + (tok.word, ), entity.sent_id, entity.word_id_start, tok.word_id+1, entity.tag)\n",
    "\n",
    "    def reducer(_entities, tok):\n",
    "        last = _entities.pop()\n",
    "        if tok.bio == 'I' and tok.tag == last.tag:\n",
    "            entity = extend_entity(last, tok)\n",
    "            _entities.append(entity)\n",
    "        elif tok.bio == 'B' or (tok.bio == 'O' and tok.tag == 'O'):\n",
    "            entity = make_entity(tok)\n",
    "            _entities.extend([last, entity])\n",
    "        # invalid token sequence tag1 => I-tag2: interpret as tag1 => B-tag2\n",
    "        elif tok.bio == 'I' and tok.tag != last.tag:\n",
    "            print('Invalid tag sequence: %s => %s' % (last, tok), file=sys.stderr)\n",
    "            entity = make_entity(tok)\n",
    "            _entities.extend([last, entity])\n",
    "        else:\n",
    "            raise ValueError('Invalid tag sequence: %s %s' % (last, tok))\n",
    "        return _entities\n",
    "\n",
    "    return reduce(reducer, toks[1:], [make_entity(toks[0]), ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def non_other(entity):\n",
    "    # type: (Entity) -> bool\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        entity (Entity): \n",
    "\n",
    "    Returns:\n",
    "        bool\n",
    "    \"\"\"\n",
    "    return entity.tag != 'O'\n",
    "\n",
    "\n",
    "def filter_entities(entities, p):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        entities (Iterable[Entity]): the entities in a sentence\n",
    "        p (Call[[Entity],bool): the predicate\n",
    "\n",
    "    Returns:\n",
    "        List(Entity): the entities filtered by predicate p\n",
    "    \"\"\"\n",
    "    return [entity for entity in entities if p(entity)]\n",
    "\n",
    "\n",
    "def drop_other_entities(entities):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        entities (Iterable[Entity]): \n",
    "\n",
    "    Returns:\n",
    "        Iterator[Entity]\n",
    "    \"\"\"\n",
    "    return filter_entities(entities, non_other)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def doc_to_tokses(lines):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        lines (Iterable[str]): the lines in a document\n",
    "\n",
    "    Returns:\n",
    "        Dictionary[str,List[List[Tokens]]]: a nested list of list of tokens,\n",
    "        with one list for each sentence, stored in a dict with keys for gold and guess\n",
    "    \"\"\"\n",
    "    \n",
    "    sents = get_sents(lines)\n",
    "    tokses = defaultdict(list)\n",
    "    for sent_id, sent in enumerate(sents):\n",
    "        for src, toks in sent_to_toks(sent, sent_id).items():\n",
    "            tokses[src].append(toks)\n",
    "    return tokses\n",
    "\n",
    "\n",
    "def flatten(nested):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        nested (Iterable[Iterable[T]]): a nested iterator\n",
    "\n",
    "    Returns:\n",
    "        List[T]: the iterator flattened into a list\n",
    "    \"\"\"\n",
    "    return [x for xs in nested for x in xs]\n",
    "\n",
    "\n",
    "def doc_to_toks(lines):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        lines (Iterator[str]): the lines in a document\n",
    "\n",
    "    Returns:\n",
    "        Dictionary[str,List[Tokens]]: a lists of all tokens in the document,\n",
    "        stored in a dict with keys for gold and guess\n",
    "    \"\"\"\n",
    "    return {src: flatten(nested)\n",
    "            for src, nested in doc_to_tokses(lines).items()}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def doc_to_entitieses(lines):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        lines (Iterator[str]): the lines in a document\n",
    "\n",
    "    Returns:\n",
    "        Dictionary[str,List[List[Entity]]]: a nested list of lists of entities,\n",
    "        stored in a dict with keys for gold and guess\n",
    "\n",
    "    \"\"\"\n",
    "    entitieses = defaultdict(list)\n",
    "    for src, tokses in doc_to_tokses(lines).items():\n",
    "        entitieses[src] = [toks_to_entities(toks) for toks in tokses]\n",
    "    return entitieses\n",
    "\n",
    "\n",
    "def doc_to_entities(lines):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        lines (Iterator[str]): the lines in a document\n",
    "\n",
    "    Returns:\n",
    "        Dictionary[str,List[Entities]]: a lists of all entities in the document,\n",
    "        stored in a dict with keys for gold and guess\n",
    "    \"\"\"\n",
    "    return {src: flatten(nested)\n",
    "            for src, nested in doc_to_entitieses(lines).items()}\n",
    "\n",
    "\n",
    "def get_tags(entities):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        entities (Iterable[Entity]): the entities in a sentence\n",
    "\n",
    "    Returns:\n",
    "        Set[str]: a set of their tags, excluding 'O'\n",
    "    \"\"\"\n",
    "    return {entity.tag for entity in entities} - {'O'}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Results = namedtuple('Results', 'gold guess correct p r f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_tagged_entities(entities):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        entities (Dict[str,List[Entity]]): \n",
    "\n",
    "    Returns:\n",
    "        Dict[str,List[Entity]]\n",
    "    \"\"\"\n",
    "    return {src: drop_other_entities(entities)\n",
    "            for src, entities in entities.items()}\n",
    "\n",
    "\n",
    "def get_correct(gold, guess):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        gold (Iterable[T]): \n",
    "        guess (Iterable[T]): \n",
    "\n",
    "    Returns:\n",
    "        Set[T]\n",
    "    \"\"\"\n",
    "    return set(gold) & set(guess)\n",
    "\n",
    "\n",
    "def get_tp(gold, guess):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        gold (Iterable[T]): \n",
    "        guess (Iterable[T]): \n",
    "\n",
    "    Returns:\n",
    "        Set[T]\n",
    "    \"\"\"\n",
    "    return get_correct(gold, guess)\n",
    "\n",
    "\n",
    "def get_fn(gold, guess):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        gold (Iterable[T]): \n",
    "        guess (Iterable[T]): \n",
    "\n",
    "    Returns:\n",
    "        Set[T]\n",
    "    \"\"\"\n",
    "    return set(gold) - set(guess)\n",
    "\n",
    "\n",
    "def get_fp(gold, guess):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        gold (Iterable[T]): \n",
    "        guess (Iterable[T]): \n",
    "\n",
    "    Returns:\n",
    "        Set[T]\n",
    "    \"\"\"\n",
    "    return set(guess) - set(gold)\n",
    "\n",
    "\n",
    "def get_tn(tp, fp, fn, _all):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        tp (Set[T]): \n",
    "        fp (Set[T]): \n",
    "        fn (Set[T]):\n",
    "        _all (Iterable[T]):\n",
    "\n",
    "    Returns:\n",
    "        Set[T]\n",
    "    \"\"\"\n",
    "    return set(_all) - tp - fp - fn\n",
    "\n",
    "\n",
    "def get_tp_fp_fn_tn(gold, guess, _all):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        gold (Iterator[T]): \n",
    "        guess (Iterator[T]): \n",
    "        _all (Iterator[T]):\n",
    "\n",
    "    Returns:\n",
    "        Tuple[Set[str],Set[str],Set[str],Set[str]]:\n",
    "    \"\"\"\n",
    "    tp = get_tp(gold, guess)\n",
    "    fp = get_fp(gold, guess)\n",
    "    fn = get_fn(gold, guess)\n",
    "    tn = get_tn(tp, fp, fn, _all)\n",
    "    return tp, fp, fn, tn\n",
    "\n",
    "\n",
    "def get_tp_fp_fn_tn_phrases(gold, guess, _all):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        gold: List[Entity]\n",
    "        guess: List[Entity]\n",
    "        _all: List[Entity]\n",
    "\n",
    "    Returns:\n",
    "        Tuple[Set[str],Set[str],Set[str],Set[str]]:\n",
    "    \"\"\"\n",
    "    all_phrases = get_phrases(_all)\n",
    "    gold_phrases = get_phrases(gold)\n",
    "    guess_phrases = get_phrases(guess)\n",
    "    correct_phrases = get_phrases(get_correct(gold, guess))\n",
    "    tp = correct_phrases\n",
    "    fp = guess_phrases - tp\n",
    "    fn = gold_phrases - tp\n",
    "    tn = get_tn(tp, fp, fn, all_phrases)\n",
    "    return tp, fp, fn, tn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def calc_results(gold_entities, guess_entities, surface_form=False):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        gold_entities (List[Entity]): the gold standard entity annotations\n",
    "        guess_entities (List[Entity]): a system's entity guesses\n",
    "        surface_form (bool): whether or not to calculate f1-scores on the entity surface forms\n",
    "\n",
    "    Returns:\n",
    "        Results: the results stored in a namedtuple\n",
    "    \"\"\"\n",
    "    # get the correct system guesses by taking the intersection of gold and guess entities,\n",
    "    # taking into account tags and document locations\n",
    "    correct_entities = get_correct(gold_entities, guess_entities)\n",
    "    if surface_form:  # count only unique surface forms when True\n",
    "        correct_entities = get_phrases_and_tags(correct_entities)\n",
    "        gold_entities = get_phrases_and_tags(gold_entities)\n",
    "        guess_entities = get_phrases_and_tags(guess_entities)\n",
    "\n",
    "    gold = len(gold_entities)\n",
    "    guess = len(guess_entities)\n",
    "    correct = len(correct_entities)\n",
    "\n",
    "    try:\n",
    "        p = correct / float(guess)\n",
    "    except ZeroDivisionError:\n",
    "        p = 0.0\n",
    "    try:\n",
    "        r = correct / float(gold)\n",
    "    except ZeroDivisionError:\n",
    "        r = 0.0\n",
    "    try:\n",
    "        f = 2.0 * p * r / (p + r)\n",
    "    except ZeroDivisionError:\n",
    "        f = 0.0\n",
    "\n",
    "    return Results(gold, guess, correct, p, r, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fmt_results(tokens, all_entities, surface_form=False):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        tokens (Dict[str,List[Tokens]): a dictionary of gold and guess tokens\n",
    "        all_entities (Dict[str,List[Entity]): a dictionary of gold and guess entities\n",
    "        surface_form (bool): whether or not to calculate f1-scores on the entity surface forms\n",
    "\n",
    "    Yield:\n",
    "        str: (near) W-NUT format evaluation results\n",
    "    \"\"\"\n",
    "    _sys = 'sys_1'\n",
    "    # throw out 'O' tags to get overall p/r/f\n",
    "    tagged_entities = get_tagged_entities(all_entities)\n",
    "    results = {'all': calc_results(all_entities['gold'], all_entities[_sys], surface_form=False),\n",
    "               'tagged': calc_results(tagged_entities['gold'], tagged_entities[_sys], surface_form),\n",
    "               'tokens': calc_results(tokens['gold'], tokens[_sys], surface_form=False)}\n",
    "\n",
    "    yield('processed %d tokens with %d phrases; ' %\n",
    "          (results['tokens'].gold, results['tagged'].gold))\n",
    "    yield('found: %d phrases; correct: %d.\\n' %\n",
    "          (results['tagged'].guess, results['tagged'].correct))\n",
    "\n",
    "    if results['tokens'].gold > 0:\n",
    "        # only use token counts for accuracy\n",
    "        yield('accuracy: %6.2f%%; ' %\n",
    "              (100. * results['tokens'].correct / results['tokens'].gold))\n",
    "        yield('precision: %6.2f%%; ' % (100. * results['tagged'].p))\n",
    "        yield('recall: %6.2f%%; ' % (100. * results['tagged'].r))\n",
    "        yield('FB1: %6.2f\\n' % (100. * results['tagged'].f))\n",
    "\n",
    "    # get results for each entity category\n",
    "    tags = get_tags(all_entities['gold'])\n",
    "    for tag in sorted(tags):\n",
    "        entities = {src: filter_entities(entities, lambda e: e.tag == tag)\n",
    "                    for src, entities in all_entities.items()}\n",
    "        results = calc_results(entities['gold'], entities[_sys], surface_form)\n",
    "        yield('%17s: ' % tag)\n",
    "        yield('precision: %6.2f%%; ' % (100. * results.p))\n",
    "        yield('recall: %6.2f%%; ' % (100. * results.r))\n",
    "        yield('FB1: %6.2f  %d\\n' % (100. * results.f, results.correct))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wnut_eval():\n",
    "    # get tokens and entities\n",
    "    lines = [line for line in fileinput.input()]\n",
    "    print(lines)\n",
    "    tokens = doc_to_toks(lines)\n",
    "    entities = doc_to_entities(lines)\n",
    "    # report results\n",
    "    print(\"### ENTITY F1-SCORES ###\")\n",
    "    for line in fmt_results(tokens, entities, surface_form=False):\n",
    "        print(line)\n",
    "    print()\n",
    "    print(\"### SURFACE FORM F1-SCORES ###\")\n",
    "    for line in fmt_results(tokens, entities, surface_form=True):\n",
    "        print(line)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
